# =============================================================================
# CG Production Data Assistant - Environment Configuration
# =============================================================================

# -----------------------------------------------------------------------------
# Storage Configuration
# -----------------------------------------------------------------------------

# Storage type: 'local' for filesystem, 's3' for AWS S3
STORAGE_TYPE=local

# Local storage path (used when STORAGE_TYPE=local)
DATA_PATH=/data

# S3 configuration (used when STORAGE_TYPE=s3)
S3_BUCKET_NAME=your-bucket-name
S3_PREFIX=production-files/
AWS_REGION=us-east-1

# AWS credentials (NOT recommended for production - use IAM roles instead)
# AWS_ACCESS_KEY_ID=your-access-key
# AWS_SECRET_ACCESS_KEY=your-secret-key

# -----------------------------------------------------------------------------
# Database Configuration
# -----------------------------------------------------------------------------

# Database URL - SQLAlchemy format
# For local SQLite:
DATABASE_URL=sqlite:///./db/metadata.db

# For AWS RDS PostgreSQL:
# DATABASE_URL=postgresql://username:password@rds-endpoint.region.rds.amazonaws.com:5432/metadata

# -----------------------------------------------------------------------------
# Application Configuration
# -----------------------------------------------------------------------------

# Logging level: DEBUG, INFO, WARNING, ERROR
LOG_LEVEL=INFO

# -----------------------------------------------------------------------------
# AWS Batch Deployment Notes
# -----------------------------------------------------------------------------
# When deploying to AWS Batch:
# 1. Set STORAGE_TYPE=s3
# 2. Set S3_BUCKET_NAME and S3_PREFIX
# 3. Set DATABASE_URL to your RDS PostgreSQL connection string
# 4. DO NOT set AWS credentials - use IAM roles attached to Batch job
# 5. Ensure IAM role has:
#    - s3:GetObject, s3:ListBucket on your S3 bucket
#    - RDS connect permissions to your database
